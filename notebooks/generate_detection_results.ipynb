{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a6efbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "sys.path.append(\"../\")\n",
    "from codes.utils.img_utils import add_bboxes_on_image\n",
    "from codes.video_handling import videoObj\n",
    "from codes.utils.evaluation import filter_preds_score_video\n",
    "from codes.time_consistency import run_on_video\n",
    "from tqdm import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b905d509",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f6e059",
   "metadata": {},
   "outputs": [],
   "source": [
    "### load_tire_annotations get the annotations from .xml CVAT file\n",
    "def load_tire_annotations(xml_path):\n",
    "    tire_annotations = {}\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    for track in root.findall('.//track'):\n",
    "        label = track.attrib['label']\n",
    "        if label == \"tire\":\n",
    "            for box in track.findall('.//box'):\n",
    "                frame_num = int(box.attrib['frame'])\n",
    "                if frame_num not in tire_annotations:\n",
    "                    tire_annotations[frame_num] = []\n",
    "                tire_annotations[frame_num].append(box.attrib)\n",
    "    return tire_annotations\n",
    "\n",
    "### generate_detection_video_with_gt returns the video with bounding boxes from detection and ground truth from annotations\n",
    "def generate_detection_video_with_gt(video_path, preds_frames, annotations_path, output_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # codec to MP4\n",
    "\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    pbar = tqdm(total=frame_count, desc=f'Processing Frames {video_path}')\n",
    "\n",
    "    tire_annotations = load_tire_annotations(annotations_path)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_num = int(cap.get(cv2.CAP_PROP_POS_FRAMES) - 1)\n",
    "        frame_key = 'frame_' + str(frame_num).zfill(5)\n",
    "        if frame_key in preds_frames:\n",
    "            instances = preds_frames[frame_key].get('instances')\n",
    "            if instances:\n",
    "                boxes = instances.pred_boxes.tensor.cpu().numpy()\n",
    "                scores = instances.scores.cpu().numpy()\n",
    "                classes = instances.pred_classes.cpu().numpy()\n",
    "\n",
    "                thickness = 3  # Define a largura da linha da bounding box\n",
    "\n",
    "                for box, score, class_id in zip(boxes, scores, classes):\n",
    "                    box = box.astype(int)\n",
    "                    cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), (0, 0, 255), thickness)\n",
    "                    cv2.putText(frame, f'{score:.2f}', (box[0], box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                                (0, 0, 255), thickness)\n",
    "\n",
    "        if frame_num in tire_annotations:\n",
    "            for box_info in tire_annotations[frame_num]:\n",
    "                xtl = int(float(box_info['xtl']))\n",
    "                ytl = int(float(box_info['ytl']))\n",
    "                xbr = int(float(box_info['xbr']))\n",
    "                ybr = int(float(box_info['ybr']))\n",
    "                cv2.rectangle(frame, (xtl, ytl), (xbr, ybr), (0, 255, 0), thickness)\n",
    "\n",
    "        frame = cv2.resize(frame, (frame_width, frame_height))\n",
    "        out.write(frame)\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "### generate_detection_video returns the video with bounding boxes from detection without ground truth from annotations\n",
    "def generate_detection_video(video_path, preds_frames, output_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # codec to MP4\n",
    "\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    pbar = tqdm(total=frame_count, desc=f'Processing Frames {video_path}')\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_key = 'frame_' + str(int(cap.get(cv2.CAP_PROP_POS_FRAMES) - 1)).zfill(5)\n",
    "        if frame_key in preds_frames:\n",
    "            instances = preds_frames[frame_key].get('instances')\n",
    "            if instances:\n",
    "                boxes = instances.pred_boxes.tensor.cpu().numpy()\n",
    "                scores = instances.scores.cpu().numpy()\n",
    "                classes = instances.pred_classes.cpu().numpy()\n",
    "\n",
    "                for box, score, class_id in zip(boxes, scores, classes):\n",
    "                    box = (box).astype(int)\n",
    "                    cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), (0, 0, 255), 2)\n",
    "                    cv2.putText(frame, f'{score:.2f}', (box[0], box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                                (0, 0, 255), 2)\n",
    "\n",
    "        frame = cv2.resize(frame, (frame_width, frame_height))\n",
    "        out.write(frame)\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "### calculates IOU score between 2 bounding boxes: ground truth and predicted ones\n",
    "def calculate_iou(ground_truth, pred):\n",
    "    ix1 = np.maximum(ground_truth[0], pred[0])\n",
    "    iy1 = np.maximum(ground_truth[1], pred[1])\n",
    "    ix2 = np.minimum(ground_truth[2], pred[2])\n",
    "    iy2 = np.minimum(ground_truth[3], pred[3])\n",
    "    i_height = np.maximum(iy2 - iy1 + 1, np.array(0.))\n",
    "    i_width = np.maximum(ix2 - ix1 + 1, np.array(0.))\n",
    "    area_of_intersection = i_height * i_width\n",
    "    gt_height = ground_truth[3] - ground_truth[1] + 1\n",
    "    gt_width = ground_truth[2] - ground_truth[0] + 1\n",
    "    pd_height = pred[3] - pred[1] + 1\n",
    "    pd_width = pred[2] - pred[0] + 1\n",
    "    area_of_union = gt_height * gt_width + pd_height * pd_width - area_of_intersection\n",
    "    iou = area_of_intersection / area_of_union\n",
    "    return iou\n",
    "\n",
    "### reads annotations in .xml CVAT files\n",
    "def read_annotations(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    annotations = defaultdict(list)\n",
    "\n",
    "    for track in root.findall('.//track'):\n",
    "        label = track.attrib['label']\n",
    "        if label == \"tire\":\n",
    "            for box in track.findall('.//box'):\n",
    "                frame = int(box.attrib['frame'])\n",
    "                xtl = float(box.attrib['xtl'])\n",
    "                ytl = float(box.attrib['ytl'])\n",
    "                xbr = float(box.attrib['xbr'])\n",
    "                ybr = float(box.attrib['ybr'])\n",
    "                annotations[frame].append({'label': label, 'box': [xtl, ytl, xbr, ybr]})\n",
    "\n",
    "    return annotations\n",
    "\n",
    "\n",
    "### returns TP, FP, FN, Pr, Rc, F1 for preds_frames (.json) and annotations (.xml CVAT)\n",
    "def calculate_metrics(preds_frames, annotations):\n",
    "    TP = FP = FN = 0\n",
    "\n",
    "    for frame, preds in preds_frames.items():\n",
    "        preds_boxes = preds['instances'].get('pred_boxes')\n",
    "        preds_scores = preds['instances'].get('scores')\n",
    "\n",
    "        if preds_boxes is not None:\n",
    "            preds_boxes = preds_boxes.tensor.cpu().numpy()\n",
    "            preds_scores = preds_scores.cpu().numpy()\n",
    "\n",
    "            annotations_frame = annotations.get(int(frame.split('_')[-1]), [])\n",
    "\n",
    "            pred_indices = []\n",
    "            annotation_indices = list(range(len(annotations_frame)))\n",
    "\n",
    "            for pred_idx, pred_box in enumerate(preds_boxes):\n",
    "                for annotation_idx, annotation in enumerate(annotations_frame):\n",
    "                    iou = calculate_iou(pred_box, annotation['box'])\n",
    "                    #print(iou)\n",
    "                    #if iou > 0.5 and annotation_idx not in annotation_indices:\n",
    "                    if iou > 0.5:\n",
    "                        pred_indices.append(pred_idx)\n",
    "                        break\n",
    "\n",
    "            TP += len(pred_indices)\n",
    "            FP += max(0, len(preds_boxes) - len(pred_indices))\n",
    "            FN += max(0, len(annotations_frame) - len(pred_indices))\n",
    "\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return TP, FP, FN, precision, recall, f1_score\n",
    "\n",
    "### load_predictions loads or computes the pkl file for predictions and returns a dictionary containing the bboxes\n",
    "def load_predictions(fold, obj, model_iter, video_name, model_name):\n",
    "    video_path = f'../../data/v1_full/videos/{video_name}.avi'\n",
    "    vid = videoObj(video_path)\n",
    "    pred_file = f\"../output/tire_test/{model_name}/mbg_{fold}_{obj}/{video_name}_preds_model_thres_{model_iter}.pkl\"\n",
    "    if os.path.isfile(pred_file):\n",
    "        print(f\"loading predictions {video_name}...\")\n",
    "        with open(pred_file, 'rb') as f:\n",
    "            preds = pickle.load(f) \n",
    "        print(\"done!\")\n",
    "    else:\n",
    "            print(f\"computing predictions {video_name}...\")\n",
    "            \n",
    "            config_file = f\"../codes/configs/mosquitoes/{model_name}.yaml\"\n",
    "                \n",
    "            cfg = get_cfg()\n",
    "            cfg.merge_from_file(config_file)\n",
    "            cfg.MODEL.WEIGHTS = os.path.join(os.path.dirname(pred_file), f\"model_{model_iter}.pth\")\n",
    "            cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.9 # set the testing threshold for this model\n",
    "            cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "            cfg.MODEL.RPN.PRE_NMS_TOPK_TRAIN = 600\n",
    "            cfg.MODEL.RPN.PRE_NMS_TOPK_TEST = 300\n",
    "            cfg.MODEL.RPN.POST_NMS_TOPK_TRAIN = 50\n",
    "            cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 50\n",
    "            \n",
    "            print(f\"weights: {cfg.MODEL.WEIGHTS}\")        \n",
    "            \n",
    "            predictor = DefaultPredictor(cfg)\n",
    "            preds = run_on_video(video_path, predictor, every=1)\n",
    "            \n",
    "            print(f\"saving predictions {video_name}...\")\n",
    "            with open(pred_file, 'wb') as f:\n",
    "                pickle.dump(preds, f)      \n",
    "            print(\"done!\")\n",
    "    preds_frames = filter_preds_score_video(preds.copy(), 0.9)\n",
    "    return preds_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cd7469",
   "metadata": {},
   "source": [
    "Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd73a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### single video\n",
    "\n",
    "fold = 'train+val'\n",
    "obj = 'tire'\n",
    "model_iter = 'final'\n",
    "video_name = 'video13'\n",
    "model_name = 'faster_rcnn_R_50_FPN_1x'\n",
    "preds_frames = load_predictions(fold, obj, model_iter, video_name, model_name)\n",
    "annotations = read_annotations(f'../../data/v1_full/annotations/{video_name}.xml')\n",
    "\n",
    "TP, FP, FN, precision, recall, f1_score = calculate_metrics(preds_frames, annotations)\n",
    "\n",
    "print(\"TP:\", TP)\n",
    "print(\"FP:\", FP)\n",
    "print(\"FN:\", FN)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n",
    "print(f'TP + FP: {TP+FP}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df944b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just checking if metrics match with total number of detections\n",
    "\n",
    "total_detections = 0\n",
    "for frame_data in preds_frames.values():\n",
    "    total_detections += len(frame_data['instances'])\n",
    "\n",
    "print(\"Total detections:\", total_detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2fb851",
   "metadata": {},
   "outputs": [],
   "source": [
    "### all videos\n",
    "\n",
    "videos = ['video01', 'video02', 'video03', 'video04', 'video05', 'video06', 'video07', 'video08', 'video09', 'video10', 'video11','video12',  'video13']\n",
    "fold = 'train+val'\n",
    "obj = 'tire'\n",
    "model_iter = 'final'\n",
    "model_name = 'faster_rcnn_R_50_FPN_1x'\n",
    "\n",
    "for video in videos:\n",
    "    preds_frames = load_predictions(fold, obj, model_iter, video, model_name)\n",
    "    annotations = read_annotations(f'../../data/v1_full/annotations/{video}.xml')\n",
    "\n",
    "    TP, FP, FN, precision, recall, f1_score = calculate_metrics(preds_frames, annotations)\n",
    "\n",
    "    print(\"TP:\", TP)\n",
    "    print(\"FP:\", FP)\n",
    "    print(\"FN:\", FN)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1_score)\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1645f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import xml.etree.ElementTree as ET\n",
    "import cv2\n",
    "\n",
    "# Function to load annotations from XML\n",
    "def load_annotations(xml_path, objects):\n",
    "    annotations = {obj: {} for obj in objects}\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    for track in root.findall('.//track'):\n",
    "        label = track.attrib['label']\n",
    "        if label in objects:\n",
    "            for box in track.findall('.//box'):\n",
    "                frame_num = int(box.attrib['frame'])\n",
    "                if frame_num not in annotations[label]:\n",
    "                    annotations[label][frame_num] = []\n",
    "                annotations[label][frame_num].append({\n",
    "                    'xtl': float(box.attrib['xtl']),\n",
    "                    'ytl': float(box.attrib['ytl']),\n",
    "                    'xbr': float(box.attrib['xbr']),\n",
    "                    'ybr': float(box.attrib['ybr'])\n",
    "                })\n",
    "    \n",
    "    return annotations\n",
    "\n",
    "# Function to generate random images with annotations for a single video\n",
    "def generate_random_images(video_path, xml_path, objects, output_dir, num_images_per_object=5):\n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    if not os.path.exists(os.path.join(output_dir, video_name)):\n",
    "        os.makedirs(os.path.join(output_dir, video_name))\n",
    "    \n",
    "    # Load annotations from XML\n",
    "    annotations = load_annotations(xml_path, objects)\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    for obj in objects:\n",
    "        if not os.path.exists(os.path.join(output_dir, video_name, obj)):\n",
    "            os.makedirs(os.path.join(output_dir, video_name, obj))\n",
    "        \n",
    "        obj_annotations = annotations[obj]\n",
    "        \n",
    "        for _ in range(num_images_per_object):\n",
    "            frame_num = random.randint(0, frame_count - 1)\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            if not ret:\n",
    "                continue\n",
    "            \n",
    "            # Check if the frame contains annotations for the current object\n",
    "            if frame_num in obj_annotations:\n",
    "                for annotation in obj_annotations[frame_num]:\n",
    "                    xtl = int(annotation['xtl'])\n",
    "                    ytl = int(annotation['ytl'])\n",
    "                    xbr = int(annotation['xbr'])\n",
    "                    ybr = int(annotation['ybr'])\n",
    "                    \n",
    "                    # Crop the frame to the bounding box area\n",
    "                    cropped_frame = frame[ytl:ybr, xtl:xbr]\n",
    "                    \n",
    "                    # Save the cropped frame with bounding box\n",
    "                    output_file = os.path.join(output_dir, video_name, obj, f'{video_name}_frame_{frame_num}_{xtl}_{ytl}_{xbr}_{ybr}.jpg')\n",
    "                    cv2.imwrite(output_file, cropped_frame)\n",
    "    \n",
    "    cap.release()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = '/nfs/proc/isabelle.melo/Mosquitoes/dataset/v1/videos/video01.avi'\n",
    "    xml_path = '/home/isabelle.melo/proc/Mosquitoes/dataset/v1/annotations-xml/video01.xml'\n",
    "    output_dir = 'generated_images'\n",
    "    objects = ['bottle']\n",
    "    \n",
    "    # Generate random images with annotations for the specified video\n",
    "    generate_random_images(video_path, xml_path, objects, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e263d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import xml.etree.ElementTree as ET\n",
    "import cv2\n",
    "\n",
    "# Function to load annotations from XML\n",
    "def load_annotations(xml_path, objects):\n",
    "    annotations = {obj: {} for obj in objects}\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    for track in root.findall('.//track'):\n",
    "        label = track.attrib['label']\n",
    "        if label in objects:\n",
    "            for box in track.findall('.//box'):\n",
    "                frame_num = int(box.attrib['frame'])\n",
    "                if frame_num not in annotations[label]:\n",
    "                    annotations[label][frame_num] = []\n",
    "                annotations[label][frame_num].append({\n",
    "                    'xtl': float(box.attrib['xtl']),\n",
    "                    'ytl': float(box.attrib['ytl']),\n",
    "                    'xbr': float(box.attrib['xbr']),\n",
    "                    'ybr': float(box.attrib['ybr'])\n",
    "                })\n",
    "    \n",
    "    return annotations\n",
    "\n",
    "# Function to generate images with annotations for frames where the object appears\n",
    "def generate_images_with_object(video_path, xml_path, object_name, output_dir):\n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Load annotations from XML\n",
    "    annotations = load_annotations(xml_path, [object_name])\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    obj_annotations = annotations[object_name]\n",
    "    \n",
    "    for frame_num in obj_annotations:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            continue\n",
    "        \n",
    "        for annotation in obj_annotations[frame_num]:\n",
    "            xtl = int(annotation['xtl'])\n",
    "            ytl = int(annotation['ytl'])\n",
    "            xbr = int(annotation['xbr'])\n",
    "            ybr = int(annotation['ybr'])\n",
    "            \n",
    "            # Crop the frame to the bounding box area\n",
    "            cropped_frame = frame[ytl:ybr, xtl:xbr]\n",
    "            \n",
    "            # Save the cropped frame with bounding box\n",
    "            output_file = os.path.join(output_dir, f'{video_name}_frame_{frame_num}_{xtl}_{ytl}_{xbr}_{ybr}.jpg')\n",
    "            cv2.imwrite(output_file, cropped_frame)\n",
    "    \n",
    "    cap.release()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = '/nfs/proc/isabelle.melo/Mosquitoes/dataset/v1/videos/video01.avi'\n",
    "    xml_path = '/home/isabelle.melo/proc/Mosquitoes/dataset/v1/annotations-xml/video01.xml'\n",
    "    output_dir = 'generated_images'\n",
    "    object_name = 'bottle'\n",
    "    \n",
    "    # Generate images with annotations for frames where the object appears\n",
    "    generate_images_with_object(video_path, xml_path, object_name, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c784055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import xml.etree.ElementTree as ET\n",
    "import cv2\n",
    "\n",
    "# Function to load annotations from XML\n",
    "def load_annotations(xml_path, objects):\n",
    "    annotations = {obj: {} for obj in objects}\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    for track in root.findall('.//track'):\n",
    "        label = track.attrib['label']\n",
    "        if label in objects:\n",
    "            for box in track.findall('.//box'):\n",
    "                frame_num = int(box.attrib['frame'])\n",
    "                if frame_num not in annotations[label]:\n",
    "                    annotations[label][frame_num] = []\n",
    "                annotations[label][frame_num].append({\n",
    "                    'xtl': float(box.attrib['xtl']),\n",
    "                    'ytl': float(box.attrib['ytl']),\n",
    "                    'xbr': float(box.attrib['xbr']),\n",
    "                    'ybr': float(box.attrib['ybr'])\n",
    "                })\n",
    "    \n",
    "    return annotations\n",
    "\n",
    "# Function to generate images with annotations for frames where the object appears\n",
    "def generate_images_with_object(video_path, xml_path, object_name, output_dir):\n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    video_dir = os.path.join(output_dir, video_name)\n",
    "    object_dir = os.path.join(video_dir, object_name)\n",
    "    \n",
    "    if not os.path.exists(object_dir):\n",
    "        os.makedirs(object_dir)\n",
    "    \n",
    "    # Load annotations from XML\n",
    "    annotations = load_annotations(xml_path, [object_name])\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    obj_annotations = annotations[object_name]\n",
    "    \n",
    "    for frame_num in obj_annotations:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            continue\n",
    "        \n",
    "        for annotation in obj_annotations[frame_num]:\n",
    "            xtl = int(annotation['xtl'])\n",
    "            ytl = int(annotation['ytl'])\n",
    "            xbr = int(annotation['xbr'])\n",
    "            ybr = int(annotation['ybr'])\n",
    "            \n",
    "            # Crop the frame to the bounding box area\n",
    "            cropped_frame = frame[ytl:ybr, xtl:xbr]\n",
    "            \n",
    "            # Save the cropped frame with bounding box\n",
    "            output_file = os.path.join(object_dir, f'{video_name}_{frame_num}.png')\n",
    "            cv2.imwrite(output_file, cropped_frame)\n",
    "    \n",
    "    cap.release()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = '/nfs/proc/isabelle.melo/Mosquitoes/dataset/v1/videos/video10.avi'\n",
    "    xml_path = '/home/isabelle.melo/proc/Mosquitoes/dataset/v1/annotations-xml/video10.xml'\n",
    "    output_dir = 'generated_images'\n",
    "    object_name = 'watertank'\n",
    "    \n",
    "    # Generate images with annotations for frames where the object appears\n",
    "    generate_images_with_object(video_path, xml_path, object_name, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
